---
title: "Study_1_Power_Simulation"
author: "Hanna Schleihauf"
date: "3/30/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
library("tidyverse")
library("styler")
library("cowplot")
library("gghalves")
library("lme4")
library("openxlsx")
library("readxl")
library("kyotil") # we want to store info about convergence issues
```

## Generate Data
```{r, include = FALSE}

set.seed(1) # set seed so that it is reproducible
n.subject <- 16 # number of subjects
min.age <- 4 # range of age (might need to be adjusted)
max.age <- 30
n.per.subject <- 36 # observations per subject
n.condition <- 2 # number of conditions
n.per.condition <- 18 # observations per subject and condition (within-subject design)
subj.id <- as.factor(paste("subj", 1:n.subject, sep = ".")) # creating a subject ids

## expected performance levels (based on other studies and intuition)
## if we expect main effects only
control.high <- 0.05 # <- reference level
control.low <- 0.10
control.none <- 0.15
gamble.high <- 0.25
gamble.low <- 0.35
gamble.none <- 0.45

## if we expect an interaction effect
# control.high <- 0.05 # <- reference level
# control.low <- 0.10
# control.none <- 0.15
# gamble.high <- 0.10
# gamble.low <- 0.35
# gamble.none <- 0.45

## start data frame
start.data <- data.frame(subj.id)
# duplicate rows according to the number obs. per subject:
start.data <- start.data[rep(
  x = 1:nrow(start.data),
  times = n.per.subject
), ]
start.data <- as.data.frame(start.data)
names(start.data) <- "subj.id"

# create balanced predictors
start.data <- data.frame(expand.grid(
  subj.id = subj.id,
  condition = c(".control", ".gamble"),
  trial.per.condition = c(1:n.per.condition)
))

## value is not completely balanced because we cannot control what the chimpanzees get
## therefore we will create two columns one for the option that chimpanzees see on the
## left and the option they see on the right (all combinations considered), in a new
## column "value" we then choose one of the options left
## or right with a 50% chance. This will be done within the loop so
## that it is different for each of the simulations.
start.data <- start.data[order(start.data$subj.id, start.data$condition, start.data$trial.per.condition), ]
start.data$value.left <- rep(c(
  ".high", ".high", ".high", ".low", ".low", ".none",
  ".high", ".low", ".none", ".low", ".none", ".none",
  ".high", ".low", ".high", ".none", ".low", ".none"
), 2 * n.subject)
start.data$value.right <- rep(c(
  ".high", ".low", ".none", ".low", ".none", ".none",
  ".high", ".high", ".high", ".low", ".low", ".none",
  ".low", ".high", ".none", ".high", ".none", ".low"
), 2 * n.subject)
## we also create predictors that we do not have any hypotheses about. In the main simulation I won't
## but it allows me to see whether the models would converge if I do.
## predictor sex
start.data$gender <-
  as.factor(rep(
    x = c(".male", ".female", ".male", ".female"),
    each = n.subject / 4
  ))[as.numeric(start.data$subj.id)]
## predictor age (might need to be adjusted)
start.data$age <-
  rep(x = runif(n = n.subject, min = 4, max = 6))[as.numeric(start.data$subj.id)]
## check whether it worked
ftable(condition ~ gender, start.data) / n.per.condition # should be 8 participants per group

## z-transformation of covariates
## z-transform age
start.data$z.age <- as.vector(scale(start.data$age))
start.data$z.trial.per.condition <- as.vector(scale(as.numeric(start.data$trial.per.condition)))

## dummy code factors and center them for random slopes
start.data$condition.gamble <-
  as.numeric(start.data$condition == levels(start.data$condition)[2])
start.data$condition.gamble.c <-
  as.numeric(start.data$condition.gamble) -
  mean(as.numeric(start.data$condition.gamble)) # centering

## I also dummy code and center gender to make the estimates unconditional of
## the reference category
start.data$gender.male <-
  as.numeric(start.data$gender == levels(start.data$gender)[2])
start.data$gender.male.c <-
  start.data$gender.male - mean(start.data$gender.male)

## checks:
## does each subject have only one sex and age?
xx <- table(start.data$subj.id, start.data$gender)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$age)
range(apply(X = xx > 0, MARGIN = 1, sum)) # should be 1 and 1

xx <- table(start.data$subj.id, start.data$condition)
range(apply(X = xx > 0, MARGIN = 1, sum))

xx <- table(start.data$subj.id, start.data$trial.per.condition)
range(apply(X = xx > 0, MARGIN = 1, sum))
```

## Calculate estimates/slopes based on our hypotheses
```{r, include = FALSE}
## to calculate slope between two point one need to (y2-y2)/(x2-x1)
## for factors it is easier, the denominator equals 1
## reference levels
intercept <-
  qlogis(control.high)

## main effect condition
s.condition.gamble <-
  qlogis(gamble.high) - qlogis(control.high)

## main effects value
s.value.low <-
  qlogis(control.low) - qlogis(control.high)

s.value.none <-
  qlogis(control.none) - qlogis(control.high)

## interaction condition*value
s.condition.gamble.value.low <-
  qlogis(gamble.low) -
  (qlogis(control.low) - qlogis(control.high)) - # value
  (qlogis(gamble.high) - qlogis(control.high)) - # gamble
  qlogis(control.high) # intercept

s.condition.gamble.value.none <-
  qlogis(gamble.none) -
  (qlogis(control.none) - qlogis(control.high)) - # value
  (qlogis(gamble.high) - qlogis(control.high)) - # gamble
  qlogis(control.high) # intercept

## no expected effects for the following predictors
s.trial.per.condition <- 0
s.gender.male <- 0
s.age <- 0

## check whether it worked
plogis(s.condition.gamble.value.low +
  s.value.low +
  s.condition.gamble +
  intercept) # should be 0.35

plogis(s.condition.gamble.value.none +
  s.value.none +
  s.condition.gamble +
  intercept) # should be 0.45
```

## Define random effects and slopes 
```{r, include = FALSE}
n.simus <- 10 # small number for testing (10), high number for actually running the code (500 - 1000)
## random intercept
## educated guess of what the random effect could be (based on the qlogis of the reference level performance)
tiny.re <- abs(intercept / 8)
moderate.re <- abs(intercept / 4)
strong.re <- abs(intercept / 2)
extrem.re <- abs(intercept * 1)
r.effects <- c(tiny.re, moderate.re) # , strong.re)
# because of the high number of interations I only looked at tiny and moderate

## random slope for condition
tiny.rs.c <- abs(s.condition.gamble / 8)
moderate.rs.c <- abs(s.condition.gamble / 4)
strong.rs.c <- abs(s.condition.gamble / 2)
extrem.rs.c <- abs(s.condition.gamble * 1)
r.slope.condition <- c(tiny.rs.c, moderate.rs.c) # , strong.rs.c )
# because of the high number of interations I only looked at tiny and moderate

## random slope for value low
tiny.rs.v.l <- abs(s.value.low / 8)
moderate.rs.v.l <- abs(s.value.low / 4)
strong.rs.v.l <- abs(s.value.low / 2)
extrem.rs.v.l <- abs(s.value.low * 1)
r.slope.value.low <- c(tiny.rs.v.l, moderate.rs.v.l) # , strong.rs.v )
# because of the high number of interations I only looked at tiny and moderate

tiny.rs.v.n <- abs(s.value.none / 8)
moderate.rs.v.n <- abs(s.value.none / 4)
strong.rs.v.n <- abs(s.value.none / 2)
extrem.rs.v.n <- abs(s.value.none * 1)
r.slope.value.none <- c(tiny.rs.v.n, moderate.rs.v.n) # , strong.rs.n )
# because of the high number of interations I only looked at tiny and moderate

## random slope for condition*value
tiny.rs.cvl <- abs(s.condition.gamble.value.low / 8)
moderate.rs.cvl <- abs(s.condition.gamble.value.low / 4)
strong.rs.cvl <- abs(s.condition.gamble.value.low / 2)
extrem.rs.cvl <- abs(s.condition.gamble.value.low * 1)
r.slope.condition.value.low <- c(tiny.rs.cvl, moderate.rs.cvl) # , strong.rs.cvl)
# because of the high number of interations I only looked at tiny and moderate

tiny.rs.cvn <- abs(s.condition.gamble.value.none / 8)
moderate.rs.cvn <- abs(s.condition.gamble.value.none / 4)
strong.rs.cvn <- abs(s.condition.gamble.value.none / 2)
extrem.rs.cvn <- abs(s.condition.gamble.value.none * 1)
r.slope.condition.value.none <- c(tiny.rs.cvn, moderate.rs.cvn) # , strong.rs.cvn)
# because of the high number of interations I only looked at tiny and moderate

## random slope for trial
r.slope.trial.per.condition <- 0
```

#Prepare simulation
```{r, echo = FALSE}
# create object to store the simulation parameters and results:
all.res <-
  data.frame(expand.grid(
    n.per.subject = n.per.subject, r.effect = r.effects, r.slope.condition = r.slope.condition,
    r.slope.value.low = r.slope.value.low, r.slope.value.none = r.slope.value.none,
    r.slope.condition.value.low = r.slope.condition.value.low, r.slope.condition.value.none = r.slope.condition.value.none,
    r.slope.trial.per.condition = r.slope.trial.per.condition, simu = 1:n.simus
  ))

# add columns for estimates
all.res$icpt <- NA
all.res$value.low <- NA
all.res$value.none <- NA
all.res$condition.gamble <- NA
all.res$z.age <- NA
all.res$gender.male.c <- NA
all.res$z.trial.per.condition <- NA
all.res$z.condition.gamble.value.low <- NA
# add columns for re.sd and warnings for full model and null model
all.res$re.sd <- NA
all.res$warns.full <- NA
all.res$warns.null <- NA
# add columns for likelihood ratio test results (p-values)
all.res$full.null.p <- NA
all.res$lrt.p.condition <- NA
all.res$lrt.p.value <- NA
all.res$lrt.p.gender.male.c <- NA
all.res$lrt.p.z.age <- NA
all.res$lrt.p.z.trial.per.condition <- NA
all.res$lrt.p.condition.value <- NA



# create vector with coefficients
coefs <- c(
  "(Intercept)" = intercept,
  "condition.gamble" = s.condition.gamble,
  "value.low" = s.value.low,
  "value.none" = s.value.none,
  "gender.male.c" = s.gender.male,
  "z.age" = s.age,
  "z.trial.per.condition" = s.trial.per.condition,
  "condition.gamble:value.low" = s.condition.gamble.value.low,
  "condition.gamble:value.none" = s.condition.gamble.value.none
)
```

#start simulation
```{r, include = FALSE}
xdata <- start.data # change start.data to xdata (just a habit)

## define control structure to make convergence more likely:
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000))

## run simulation
for (i in 1:nrow(all.res)) {

  ## pick whether chimpanzee pulls high value, low value or no reward
  xdata$value <- NA

  for (j in 1:nrow(xdata)) {
    # dummy code factors and center them for random slopes
    xdata$value[j] <- sample(c(xdata$value.left[j], xdata$value.right[j]), 1, prob = c(0.5, 0.5))
  }

  ## dummy code the interaction of value
  xdata$value <- as.factor(xdata$value)
  xdata$value.low <-
    as.numeric(xdata$value == levels(xdata$value)[2])
  xdata$value.low.c <-
    as.numeric(xdata$value.low) -
    mean(as.numeric(xdata$value.low)) # centering
  xdata$value.none <-
    as.numeric(xdata$value == levels(xdata$value)[3])
  xdata$value.none.c <-
    as.numeric(xdata$value.none) -
    mean(as.numeric(xdata$value.none)) # centering

  ## dummy code the interaction of condition and value
  xdata$condition.gamble.value.low <-
    ifelse((xdata$condition == ".gamble" & xdata$value == ".low"), 1, 0)
  xdata$condition.gamble.value.low.c <-
    as.numeric(xdata$condition.gamble.value.low) -
    mean(as.numeric(xdata$condition.gamble.value.low)) # centering
  xdata$condition.gamble.value.none <-
    ifelse((xdata$condition == ".gamble" & xdata$value == ".none"), 1, 0)
  xdata$condition.gamble.value.none.c <-
    as.numeric(xdata$condition.gamble.value.none) -
    mean(as.numeric(xdata$condition.gamble.value.none)) # centering

  ## create model matrix
  m.mat <- model.matrix(object = ~ condition * value + gender.male.c + z.age + z.trial.per.condition, data = xdata) # create model matrix
  names(coefs)
  colnames(m.mat)
  ## create LP wrt fixed effects
  LP <- m.mat[, names(coefs)] %*% coefs

  set.seed(i + 3) # allows to later replicate individual simulations

  ## add random effect to linear predictor:
  LP <- LP + rnorm(n = n.subject, sd = all.res[i, "r.effect"])[as.numeric(xdata$subj.id)] +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.condition"])[as.numeric(xdata$subj.id)] * xdata$condition.gamble +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.value.low"])[as.numeric(xdata$subj.id)] * xdata$value.low +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.value.none"])[as.numeric(xdata$subj.id)] * xdata$value.none +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.condition.value.low"])[as.numeric(xdata$subj.id)] * xdata$condition.gamble.value.low +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.condition.value.none"])[as.numeric(xdata$subj.id)] * xdata$condition.gamble.value.none +
    rnorm(n = n.subject, sd = all.res[i, "r.slope.trial.per.condition"])[as.numeric(xdata$subj.id)] * xdata$z.trial.per.condition

  ## generate response:
  xdata$searching <- rbinom(n = nrow(xdata), size = 1, prob = exp(LP) / (1 + exp(LP)))
  ftable(searching ~ condition + value, xdata)

  ## here I decided to really only look at the fixed effects of interest
  ## fit full model:
  full <- keepWarnings(glmer(searching ~
  (condition + value)^2 + # gender.male.c + z.age + z.trial.per.condition +
    (1 + (condition.gamble.c * (value.low.c + value.none.c)) + z.trial.per.condition || subj.id),
  data = xdata, family = binomial, control = contr
  ))

  ## fit null model:
  null <- keepWarnings(glmer(searching ~
  1 +
    (1 + (condition.gamble.c * (value.low.c + value.none.c)) + z.trial.per.condition || subj.id),
  data = xdata, family = binomial, control = contr
  ))

  ## fit reduced model with only main effects:
  red1 <- keepWarnings(glmer(searching ~
  (condition + value) + # gender.male.c + z.age + z.trial.per.condition +
    (1 + (condition.gamble.c * (value.low.c + value.none.c)) + z.trial.per.condition || subj.id),
  data = xdata, family = binomial, control = contr
  ))


  ## store results:
  all.res[i, c(
    "icpt", "condition.gamble", "value.low", "value.none", # "gender.male.c", "z.age", "z.trial.per.condition",
    "condition.gamble:value.low", "condition.gamble:value.none"
  )] <- fixef(full$value)

  all.res[i, "re.sd"] <- as.data.frame(summary(full$value)$varcor)[1, "sdcor"]
  all.res[i, "warns.full"] <- nchar(paste(full$warnings, collapse = ""))
  all.res[i, "warns.null"] <- nchar(paste(null$warnings, collapse = ""))
  all.res[i, "full.null.p"] <-
    as.data.frame(anova(null$value, full$value, test = "Chisq"))[2, "Pr(>Chisq)"]

  xx <- drop1(full$value, test = "Chisq")
  all.res[i, "lrt.p.condition.value"] <- as.data.frame(xx)["condition:value", "Pr(Chi)"]

  ## ftable(searching ~ condition + value, xdata)

  xx <- drop1(red1$value, test = "Chisq")
  all.res[i, "lrt.p.condition"] <- as.data.frame(xx)["condition", "Pr(Chi)"]
  all.res[i, "lrt.p.value"] <- as.data.frame(xx)["value", "Pr(Chi)"]
  # all.res[i, "lrt.p.gender.male.c"] <- as.data.frame(xx)["gender.male.c", "Pr(Chi)"]
  # all.res[i, "lrt.p.z.age"] <- as.data.frame(xx)["z.age", "Pr(Chi)"]
  # all.res[i, "lrt.p.z.trial.per.condition"] <- as.data.frame(xx)["z.trial.per.condition", "Pr(Chi)"]


  print(i)
}

save.image("counterfactual_power_sim.RData")

load("counterfactual_power_sim.RData")
```

## Evaluation of results 
## Check how many warnings we have gotten
```{r, echo = FALSE}
## full model
all.res1 <- all.res
tapply(
  X = all.res1[, "warns.full"] > 0, INDEX = all.res1[, c("r.effect", "r.slope.condition", "r.slope.value.low", "r.slope.value.none", "r.slope.condition.value.low", "r.slope.condition.value.none")],
  FUN = sum
)

sum(all.res1[, "warns.full"] > 0)

## null model
tapply(
  X = all.res1[, "warns.null"] > 0, INDEX = all.res1[, c("r.effect")],
  FUN = sum
)
```

## Only models that converged (no warnings) are evaluated from here on:  
```{r include=FALSE}
all.res2 <- subset(all.res1, warns.full == 0)
```

## How many models converged, have a significant full-null model comparison, and a significant LRT of condition, value, or condition*value?  
```{r echo=FALSE}

lrt.data1 <- all.res2 %>%
  group_by(
    r.effect, r.slope.condition, r.slope.value.low, r.slope.value.none,
    r.slope.condition.value.low, r.slope.condition.value.none
  ) %>%
  summarise(
    n.lrt = n.simus, # length(lrt.p.condition.value),

    full.null.p.mean = mean(full.null.p), # mean full-null model p-value of the models that converged
    n.sign.full.null.p = length(full.null.p[full.null.p <= 0.05]), # number of significant full-null model comparisons
    n.full.null = length(full.null.p), # number of iterations
    proportion.sign.full.null = length(full.null.p[full.null.p < 0.05]) / n.simus,
    lrt.p.condition.value = mean(lrt.p.condition.value),
    n.sign.lrt.condition.value = sum(lrt.p.condition.value <= 0.05),
    pwr.condition.value = mean(lrt.p.condition.value <= 0.05),
    prop.sign.lrt.condition.value = length(lrt.p.condition.value[lrt.p.condition.value <= 0.05]) / n.simus,
    lrt.p.condition = mean(lrt.p.condition),
    n.sign.lrt.condition = sum(lrt.p.condition <= 0.05),
    pwr.condition = mean(lrt.p.condition <= 0.05),
    prop.sign.lrt.condition = length(lrt.p.condition[lrt.p.condition <= 0.05]) / n.simus,
    lrt.p.value = mean(lrt.p.value),
    n.sign.lrt.value = sum(lrt.p.value <= 0.05),
    pwr.value = mean(lrt.p.value <= 0.05),
    prop.sign.lrt.value = length(lrt.p.value[lrt.p.value <= 0.05]) / n.simus
  )

lrt.data1

## overall mean power (all different slopes considered)
mean(lrt.data1$pwr.condition)
mean(lrt.data1$pwr.condition)
mean(lrt.data1$pwr.value)

## here we look at power for c
lrt.data2 <- all.res2 %>%
  filter(full.null.p < 0.05) %>%
  group_by(
    r.effect, r.slope.condition, r.slope.value.low, r.slope.value.none,
    r.slope.condition.value.low, r.slope.condition.value.none
  ) %>%
  summarise(
    n.lrt = n.simus, # length(lrt.p.condition.value),
    lrt.p.condition.value = mean(lrt.p.condition.value),
    n.sign.lrt.condition.value = sum(lrt.p.condition.value <= 0.05),
    pwr.condition.value = mean(lrt.p.condition.value <= 0.05),
    prop.sign.lrt.condition.value = length(lrt.p.condition.value[lrt.p.condition.value <= 0.05]) / n.simus,
    lrt.p.condition = mean(lrt.p.condition),
    n.sign.lrt.condition = sum(lrt.p.condition <= 0.05),
    pwr.condition = mean(lrt.p.condition <= 0.05),
    prop.sign.lrt.condition = length(lrt.p.condition[lrt.p.condition <= 0.05]) / n.simus,
    lrt.p.value = mean(lrt.p.value),
    n.sign.lrt.value = sum(lrt.p.value <= 0.05),
    pwr.value = mean(lrt.p.value <= 0.05),
    prop.sign.lrt.value = length(lrt.p.value[lrt.p.value <= 0.05]) / n.simus
  )

lrt.data2
```
